export interface LLMConfig {
    model?: string;
    thinking?: 'enabled' | 'disabled';
    caching?: 'enabled' | 'disabled';
    temperature?: number;
    streaming?: boolean;
}
export declare const LLMDefaults: {
    MODEL: string;
    THINKING: "disabled";
    CACHING: "disabled";
    TEMPERATURE: number;
    STREAMING: boolean;
};
export interface ContentPart {
    type: 'text' | 'image_url' | 'video_url';
    text?: string;
    image_url?: {
        url: string;
        detail?: 'high' | 'low';
    };
    video_url?: {
        url: string;
        fps?: number | null;
    };
}
export interface Message {
    role: 'system' | 'user' | 'assistant';
    content: string | ContentPart[];
}
export interface LLMResponse {
    content: string;
}
//# sourceMappingURL=models.d.ts.map