"use strict";
/**
 * S3 Storage client module
 */
var __importDefault = (this && this.__importDefault) || function (mod) {
    return (mod && mod.__esModule) ? mod : { "default": mod };
};
Object.defineProperty(exports, "__esModule", { value: true });
exports.S3Storage = void 0;
const client_s3_1 = require("@aws-sdk/client-s3");
const lib_storage_1 = require("@aws-sdk/lib-storage");
const stream_1 = require("stream");
const crypto_1 = require("crypto");
const path_1 = __importDefault(require("path"));
const models_1 = require("./models");
function getStorageToken() {
    return process.env.COZE_WORKLOAD_IDENTITY_API_KEY || null;
}
class S3Storage {
    constructor(config = {}) {
        this.client = null;
        this.endpointUrl = process.env.COZE_BUCKET_ENDPOINT_URL || config.endpointUrl || '';
        this.accessKey = config.accessKey || '';
        this.secretKey = config.secretKey || '';
        this.bucketName = process.env.COZE_BUCKET_NAME || config.bucketName || '';
        this.region = config.region || models_1.S3Config.DEFAULT_REGION;
    }
    getClient() {
        if (!this.client) {
            if (!this.endpointUrl) {
                throw new Error('Storage endpoint not configured: Set COZE_BUCKET_ENDPOINT_URL');
            }
            this.client = new client_s3_1.S3Client({
                endpoint: this.endpointUrl,
                region: this.region,
                credentials: {
                    accessKeyId: this.accessKey,
                    secretAccessKey: this.secretKey,
                },
                forcePathStyle: true,
            });
            this.client.middlewareStack.add((next) => async (args) => {
                const token = getStorageToken();
                if (token && args.request?.headers) {
                    args.request.headers['x-storage-token'] = token;
                }
                return next(args);
            }, { step: 'build', name: 'injectStorageToken' });
        }
        return this.client;
    }
    generateObjectKey(originalName) {
        const ext = path_1.default.extname(originalName).toLowerCase();
        const stem = path_1.default.basename(originalName, ext);
        const uniq = (0, crypto_1.randomUUID)().replace(/-/g, '').slice(0, 8);
        return path_1.default.join(path_1.default.dirname(originalName), `${stem}_${uniq}${ext}`);
    }
    resolveBucket(bucket) {
        const targetBucket = bucket || process.env.COZE_BUCKET_NAME || this.bucketName;
        if (!targetBucket) {
            throw new Error('Bucket not configured: Provide bucket or set COZE_BUCKET_NAME');
        }
        return targetBucket;
    }
    validateFileName(name) {
        const msg = 'Invalid file name: must be 1-1024 bytes, only letters/numbers/._-/, no spaces or special chars, not start/end with /, no //';
        if (!name || !name.trim())
            throw new Error(msg + ' (empty)');
        if (Buffer.byteLength(name, 'utf-8') > 1024)
            throw new Error(msg + ' (>1024 bytes)');
        if (name.startsWith('/') || name.endsWith('/'))
            throw new Error(msg + ' (starts/ends with /)');
        if (name.includes('//'))
            throw new Error(msg + ' (contains //)');
        if (!models_1.FILE_NAME_ALLOWED_RE.test(name)) {
            const bad = name.match(/[^A-Za-z0-9._\-/]/);
            throw new Error(msg + ` (invalid char: ${bad?.[0]})`);
        }
    }
    async uploadFile(options) {
        const { fileContent, fileName, contentType = 'application/octet-stream', bucket } = options;
        this.validateFileName(fileName);
        const client = this.getClient();
        const objectKey = this.generateObjectKey(fileName);
        const targetBucket = this.resolveBucket(bucket);
        await client.send(new client_s3_1.PutObjectCommand({
            Bucket: targetBucket,
            Key: objectKey,
            Body: fileContent,
            ContentType: contentType,
        }));
        return objectKey;
    }
    async readFile(options) {
        const { fileKey, bucket } = options;
        const client = this.getClient();
        const targetBucket = this.resolveBucket(bucket);
        const response = await client.send(new client_s3_1.GetObjectCommand({ Bucket: targetBucket, Key: fileKey }));
        if (!response.Body) {
            throw new Error('S3 GetObject returned no Body');
        }
        const chunks = [];
        for await (const chunk of response.Body) {
            chunks.push(Buffer.from(chunk));
        }
        return Buffer.concat(chunks);
    }
    async deleteFile(options) {
        const { fileKey, bucket } = options;
        const client = this.getClient();
        const targetBucket = this.resolveBucket(bucket);
        await client.send(new client_s3_1.DeleteObjectCommand({ Bucket: targetBucket, Key: fileKey }));
        return true;
    }
    async fileExists(options) {
        const { fileKey, bucket } = options;
        const client = this.getClient();
        const targetBucket = this.resolveBucket(bucket);
        try {
            await client.send(new client_s3_1.HeadObjectCommand({ Bucket: targetBucket, Key: fileKey }));
            return true;
        }
        catch (e) {
            if (e.name === 'NotFound' || e.$metadata?.httpStatusCode === 404) {
                return false;
            }
            console.error('Error checking file existence:', e);
            return false;
        }
    }
    async listFiles(options = {}) {
        const { prefix, bucket, maxKeys = models_1.S3Config.DEFAULT_MAX_KEYS, continuationToken } = options;
        if (maxKeys <= 0 || maxKeys > 1000) {
            throw new Error('maxKeys must be between 1 and 1000');
        }
        const client = this.getClient();
        const targetBucket = this.resolveBucket(bucket);
        const response = await client.send(new client_s3_1.ListObjectsV2Command({
            Bucket: targetBucket,
            MaxKeys: maxKeys,
            Prefix: prefix,
            ContinuationToken: continuationToken,
        }));
        const keys = (response.Contents || []).filter((item) => item.Key).map((item) => item.Key);
        return {
            keys,
            isTruncated: response.IsTruncated || false,
            nextContinuationToken: response.NextContinuationToken,
        };
    }
    async generatePresignedUrl(options) {
        const { key, bucket, expireTime = models_1.S3Config.DEFAULT_PRESIGNED_EXPIRE_TIME } = options;
        const token = getStorageToken();
        if (!token) {
            throw new Error('Failed to get x-storage-token: Set COZE_WORKLOAD_IDENTITY_API_KEY');
        }
        const signBase = process.env.COZE_BUCKET_ENDPOINT_URL || this.endpointUrl;
        if (!signBase) {
            throw new Error('Sign endpoint not configured: Set COZE_BUCKET_ENDPOINT_URL');
        }
        const signUrlEndpoint = signBase.replace(/\/$/, '') + '/sign-url';
        const targetBucket = this.resolveBucket(bucket);
        const response = await fetch(signUrlEndpoint, {
            method: 'POST',
            headers: {
                'Content-Type': 'application/json',
                'x-storage-token': token,
            },
            body: JSON.stringify({
                bucket_name: targetBucket,
                path: key,
                expire_time: expireTime,
            }),
        });
        if (!response.ok) {
            throw new Error(`Failed to generate presigned URL: ${response.status}`);
        }
        const text = await response.text();
        const contentType = response.headers.get('content-type') || '';
        if (contentType.includes('application/json') || text.trim().startsWith('{')) {
            try {
                const obj = JSON.parse(text);
                if (obj.data?.url)
                    return obj.data.url;
                if (obj.url || obj.signed_url || obj.presigned_url) {
                    return obj.url || obj.signed_url || obj.presigned_url;
                }
                throw new Error('Sign service response missing url field');
            }
            catch {
                return text;
            }
        }
        return text;
    }
    async streamUploadFile(options) {
        const { stream, fileName, contentType = 'application/octet-stream', bucket } = options;
        const client = this.getClient();
        const objectKey = this.generateObjectKey(fileName);
        const targetBucket = this.resolveBucket(bucket);
        const upload = new lib_storage_1.Upload({
            client,
            params: {
                Bucket: targetBucket,
                Key: objectKey,
                Body: stream,
                ContentType: contentType,
            },
        });
        await upload.done();
        return objectKey;
    }
    async uploadFromUrl(options) {
        const { url, bucket, timeout = models_1.S3Config.DEFAULT_UPLOAD_TIMEOUT } = options;
        const controller = new AbortController();
        const timeoutId = setTimeout(() => controller.abort(), timeout);
        try {
            const response = await fetch(url, { signal: controller.signal });
            if (!response.ok) {
                throw new Error(`Failed to fetch URL: ${response.status}`);
            }
            const urlObj = new URL(url);
            const fileName = path_1.default.basename(decodeURIComponent(urlObj.pathname)) || 'file';
            const contentType = response.headers.get('content-type') || 'application/octet-stream';
            const buffer = Buffer.from(await response.arrayBuffer());
            return this.uploadFile({ fileContent: buffer, fileName, contentType, bucket });
        }
        finally {
            clearTimeout(timeoutId);
        }
    }
    async chunkUploadFile(options) {
        const { chunks, fileName, contentType = 'application/octet-stream', bucket } = options;
        const client = this.getClient();
        const objectKey = this.generateObjectKey(fileName);
        const targetBucket = this.resolveBucket(bucket);
        const stream = stream_1.Readable.from(chunks);
        const upload = new lib_storage_1.Upload({
            client,
            params: {
                Bucket: targetBucket,
                Key: objectKey,
                Body: stream,
                ContentType: contentType,
            },
        });
        await upload.done();
        return objectKey;
    }
}
exports.S3Storage = S3Storage;
exports.default = S3Storage;
//# sourceMappingURL=client.js.map